{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Santander Value Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to Epsilon research, 80% of customers are more likely to do business with you if you provide personalized service. Banking is no exception.\n",
    "\n",
    "The digitalization of everyday lives means that customers expect services to be delivered in a personalized and timely manner… and often before they´ve even realized they need the service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Santander Group aims to go a step beyond recognizing that there is a need to provide a customer a financial service and intends to determine the amount or value of the customer's transaction. This means anticipating customer needs in a more concrete, but also simple and personal way. With so many choices for financial services, this need is greater now than ever before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify the value of transactions for each potential customer. This is a first step that Santander needs to nail in order to personalize their services at scale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Technical Overview\n",
    "\n",
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are provided with an anonymized dataset containing numeric feature variables, the numeric target column, and a string ID column. This dataset is composed of\n",
    "\n",
    "- The training set in the file train.csv\n",
    "- The testing set in the file test.csv.\n",
    "\n",
    "## Evaluation Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The evaluation metric for this competition is Root Mean Squared Logarithmic Error. The RMSLE is calculated as\n",
    "\n",
    "![RMSE](rmse.svg)\n",
    "\n",
    "where\n",
    "\n",
    "- $\\epsilon$ is the RMSLE value (score)\n",
    "- $n$ is the total number of observations in the (public/private) data set,\n",
    "- $p_i$ is your prediction of target, and\n",
    "- $a_i$ is the actual target for $i$.\n",
    "- $\\log(x)$ is the natural logarithm of $x$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to predict the value of the target column in the test set where $\\epsilon$ has to be as closed as $0$. For every row in the test.csv, submission files has to contain two columns: ID and target. The ID corresponds to the column of that ID in the test.csv."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Acquisition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective is to get the train and test data sets and extract basic information before starting the data exploratory phase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Source\n",
    "\n",
    "The data come from Kaggle and are downloaded here.https://www.kaggle.com/c/santander-value-prediction-challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Basic Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to know how much data do we have in our data sets to help us determining a list of algorithms that will suit better to solve the problem.\n",
    "\n",
    "- Number of rows\n",
    "- Number of columns\n",
    "- Percentage: number of rows of a data set / total number of rows of test + train sets * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# dataset reading\n",
    "train = pandas.read_csv(\"train.csv\")\n",
    "test= pandas.read_csv(\"test.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the number of features is slightly greater than the number of observations. In such case, we can use:\n",
    "\n",
    "- Dimension reduction algorithms like PCA (Principal Component Analysis) in order to group features and then reduce their number.\n",
    "\n",
    "- Regularized models like the SVM (Support Vector Machine), Ridge, Lasso or Elastic net because they use the regularization parameter which make the algorithm resistant against the over-fitting. However, the choice of that parameter has to be judicious."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4459 entries, 0 to 4458\n",
      "Columns: 4993 entries, ID to 9fc776466\n",
      "dtypes: float64(1845), int64(3147), object(1)\n",
      "memory usage: 169.9+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 49342 entries, 0 to 49341\n",
      "Columns: 4992 entries, ID to 9fc776466\n",
      "dtypes: float64(4991), object(1)\n",
      "memory usage: 1.8+ GB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(train.info())\n",
    "print(test.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>target</th>\n",
       "      <th>48df886f9</th>\n",
       "      <th>0deb4b6a8</th>\n",
       "      <th>34b15f335</th>\n",
       "      <th>a8cb14b00</th>\n",
       "      <th>2f0771a37</th>\n",
       "      <th>30347e683</th>\n",
       "      <th>d08d1fbe3</th>\n",
       "      <th>6ee66e115</th>\n",
       "      <th>...</th>\n",
       "      <th>3ecc09859</th>\n",
       "      <th>9281abeea</th>\n",
       "      <th>8675bec0b</th>\n",
       "      <th>3a13ed79a</th>\n",
       "      <th>f677d4d13</th>\n",
       "      <th>71b203550</th>\n",
       "      <th>137efaa80</th>\n",
       "      <th>fb36b89d9</th>\n",
       "      <th>7e293fbaf</th>\n",
       "      <th>9fc776466</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000d6aaf2</td>\n",
       "      <td>38000000.000000000</td>\n",
       "      <td>0.000000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000000</td>\n",
       "      <td>0.000000000</td>\n",
       "      <td>0.000000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fbd867</td>\n",
       "      <td>600000.000000000</td>\n",
       "      <td>0.000000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000000</td>\n",
       "      <td>0.000000000</td>\n",
       "      <td>0.000000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0027d6b71</td>\n",
       "      <td>10000000.000000000</td>\n",
       "      <td>0.000000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000000</td>\n",
       "      <td>0.000000000</td>\n",
       "      <td>0.000000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0028cbf45</td>\n",
       "      <td>2000000.000000000</td>\n",
       "      <td>0.000000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000000</td>\n",
       "      <td>0.000000000</td>\n",
       "      <td>0.000000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>002a68644</td>\n",
       "      <td>14400000.000000000</td>\n",
       "      <td>0.000000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000000</td>\n",
       "      <td>0.000000000</td>\n",
       "      <td>0.000000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4993 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID             target   48df886f9  0deb4b6a8   34b15f335  a8cb14b00  \\\n",
       "0  000d6aaf2 38000000.000000000 0.000000000          0 0.000000000          0   \n",
       "1  000fbd867   600000.000000000 0.000000000          0 0.000000000          0   \n",
       "2  0027d6b71 10000000.000000000 0.000000000          0 0.000000000          0   \n",
       "3  0028cbf45  2000000.000000000 0.000000000          0 0.000000000          0   \n",
       "4  002a68644 14400000.000000000 0.000000000          0 0.000000000          0   \n",
       "\n",
       "   2f0771a37  30347e683  d08d1fbe3  6ee66e115    ...       3ecc09859  \\\n",
       "0          0          0          0          0    ...     0.000000000   \n",
       "1          0          0          0          0    ...     0.000000000   \n",
       "2          0          0          0          0    ...     0.000000000   \n",
       "3          0          0          0          0    ...     0.000000000   \n",
       "4          0          0          0          0    ...     0.000000000   \n",
       "\n",
       "    9281abeea   8675bec0b  3a13ed79a  f677d4d13  71b203550  137efaa80  \\\n",
       "0 0.000000000 0.000000000          0          0          0          0   \n",
       "1 0.000000000 0.000000000          0          0          0          0   \n",
       "2 0.000000000 0.000000000          0          0          0          0   \n",
       "3 0.000000000 0.000000000          0          0          0          0   \n",
       "4 0.000000000 0.000000000          0          0          0          0   \n",
       "\n",
       "   fb36b89d9  7e293fbaf  9fc776466  \n",
       "0          0          0          0  \n",
       "1          0          0          0  \n",
       "2          0          0          0  \n",
       "3          0          0          0  \n",
       "4          0          0          0  \n",
       "\n",
       "[5 rows x 4993 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop('target', axis=1)\n",
    "X = X.drop('ID', axis=1)\n",
    "y = train['target']\n",
    "\n",
    "X_test = test\n",
    "X_test = X_test.drop('ID', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.apply(lambda x: np.log(x+1))\n",
    "y = y.apply(lambda x: np.log(x+1))\n",
    "X_test = X_test.apply(lambda x: np.log(x+1))\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed: 59.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,\n",
       "           oob_score=False, random_state=42, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestRegressor(n_estimators=1000, random_state=42, verbose=1)\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.5s finished\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.387853008115715\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_valid)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "def rmsle(real, predicted):\n",
    "    sum=0.0\n",
    "    for x in range(len(predicted)):\n",
    "        if predicted[x]<0 or real[x]<0: #check for negative values\n",
    "            continue\n",
    "        p = np.log(predicted[x]+1)\n",
    "        r = np.log(real[x]+1)\n",
    "        sum = sum + (p - r)**2\n",
    "    return (sum/len(predicted))**0.5\n",
    "\n",
    "predictions = np.exp(predictions)-1\n",
    "real = np.exp(y_valid.values)-1\n",
    "\n",
    "print(rmsle(real, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:   51.3s finished\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prediction  = pandas.DataFrame()\n",
    "prediction['ID'] = test['ID']\n",
    "prediction.head()\n",
    "prediction['target'] = model.predict(X_test)\n",
    "prediction['target'] = prediction['target'].apply(lambda x: np.exp(x) - 1)\n",
    "\n",
    "prediction.to_csv('result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
