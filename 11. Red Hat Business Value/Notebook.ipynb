{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement\n",
    "\n",
    "The high-level problem statement is mentioned in the competition’s description page. It highlights the problem that deals with predicting high-value customers for their business based on the operational interaction data and thereby helping the company effectively prioritize resources to generate more business and serve its customers better.\n",
    "\n",
    "Let’s have a look at the problem statement from a more business-centric view. We will start by understanding the customer better. The organization is an American multinational software company that provides open source software products to the enterprise community. Their primary product is Red Hat Enterprise Linux, the most popular distribution of Linux OS, used by various large enterprises. In its services, it helps organizations align their IT strategies by providing enterprise-grade\n",
    "solutions through an open business model and an affordable, predictable subscription model. These subscriptions from large enterprise customers create a substantial part of their revenue, and therefore it is of paramount importance for them to understand their valuable customers and serve them better by prioritizing resources and strategies to drive improved\n",
    "business value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How Can We Identify a Potential Customer?\n",
    "\n",
    "Red Hat has been in existence for over 25 years. In the long stint of\n",
    "business, they have accumulated and captured a vast amount of data from\n",
    "customer interactions and their descriptive attributes. This rich source\n",
    "of data could be a gold mine of patterns that can help in identifying a\n",
    "potential customer by studying the vast and complex historical patterns in\n",
    "the interaction data.\n",
    "\n",
    "\n",
    "With the ever-growing popularity and prowess of DL, we can develop\n",
    "a DNN that can learn from historic customer attributes and operational\n",
    "interaction data to understand the deep patterns and predict whether\n",
    "a new customer will potentially be a high-value customer for various\n",
    "business services.\n",
    "\n",
    "Therefore, we will develop and train a DNN to learn the chances that a\n",
    "customer will be a potential high-value customer, using various customer\n",
    "attributes and operational interaction attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, merge, Convolution2D, MaxPooling2D, UpSampling2D,ZeroPadding2D\n",
    "from keras.optimizers import Adam , RMSprop, Adadelta, SGD\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import backend as K\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.advanced_activations import PReLU,ELU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_train = pd.read_csv('data2/act_train.csv')\n",
    "act_test = pd.read_csv('data2/act_test.csv')\n",
    "people = pd.read_csv('data2/people.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the test IDs for Kaggle submission\n",
    "test_ids = act_test['activity_id']\n",
    "\n",
    "def preprocess_acts(data, train_set=True):\n",
    "    \n",
    "    # Getting rid of data feature for now\n",
    "    data = data.drop(['date', 'activity_id'], axis=1)\n",
    "    if(train_set):\n",
    "        data = data.drop(['outcome'], axis=1)\n",
    "    \n",
    "    ## Split off _ from people_id\n",
    "    data['people_id'] = data['people_id'].apply(lambda x: x.split('_')[1])\n",
    "    data['people_id'] = pd.to_numeric(data['people_id']).astype(int)\n",
    "    \n",
    "    columns = list(data.columns)\n",
    "    \n",
    "    # Convert strings to ints\n",
    "    for col in columns[1:]:\n",
    "        data[col] = data[col].fillna('type 0')\n",
    "        data[col] = data[col].apply(lambda x: x.split(' ')[1])\n",
    "        data[col] = pd.to_numeric(data[col]).astype(int)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_people(data):\n",
    "    \n",
    "    # TODO refactor this duplication\n",
    "    data = data.drop(['date'], axis=1)\n",
    "    data['people_id'] = data['people_id'].apply(lambda x: x.split('_')[1])\n",
    "    data['people_id'] = pd.to_numeric(data['people_id']).astype(int)\n",
    "    \n",
    "    #  Values in the people df is Booleans and Strings    \n",
    "    columns = list(data.columns)\n",
    "    bools = columns[11:]\n",
    "    strings = columns[1:11]\n",
    "    \n",
    "    for col in bools:\n",
    "        data[col] = pd.to_numeric(data[col]).astype(int)        \n",
    "    for col in strings:\n",
    "        data[col] = data[col].fillna('type 0')\n",
    "        data[col] = data[col].apply(lambda x: x.split(' ')[1])\n",
    "        data[col] = pd.to_numeric(data[col]).astype(int)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Preprocess each df\n",
    "peeps = preprocess_people(people)\n",
    "actions_train = preprocess_acts(act_train)\n",
    "actions_test = preprocess_acts(act_test, train_set=False)\n",
    "\n",
    "# Merege into a unified table\n",
    "\n",
    "# Training \n",
    "features = actions_train.merge(peeps, how='left', on='people_id')\n",
    "labels = act_train['outcome']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>people_id</th>\n",
       "      <th>activity_category</th>\n",
       "      <th>char_1_x</th>\n",
       "      <th>char_2_x</th>\n",
       "      <th>char_3_x</th>\n",
       "      <th>char_4_x</th>\n",
       "      <th>char_5_x</th>\n",
       "      <th>char_6_x</th>\n",
       "      <th>char_7_x</th>\n",
       "      <th>char_8_x</th>\n",
       "      <th>...</th>\n",
       "      <th>char_29</th>\n",
       "      <th>char_30</th>\n",
       "      <th>char_31</th>\n",
       "      <th>char_32</th>\n",
       "      <th>char_33</th>\n",
       "      <th>char_34</th>\n",
       "      <th>char_35</th>\n",
       "      <th>char_36</th>\n",
       "      <th>char_37</th>\n",
       "      <th>char_38</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>79634</th>\n",
       "      <td>105776</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1739874</th>\n",
       "      <td>381274</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21887</th>\n",
       "      <td>103828</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1311241</th>\n",
       "      <td>315216</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1222139</th>\n",
       "      <td>299252</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346863</th>\n",
       "      <td>154083</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714117</th>\n",
       "      <td>220439</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1276568</th>\n",
       "      <td>308846</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026388</th>\n",
       "      <td>273835</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1669654</th>\n",
       "      <td>370270</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         people_id  activity_category  char_1_x  char_2_x  char_3_x  char_4_x  \\\n",
       "79634       105776                  3         0         0         0         0   \n",
       "1739874     381274                  2         0         0         0         0   \n",
       "21887       103828                  3         0         0         0         0   \n",
       "1311241     315216                  2         0         0         0         0   \n",
       "1222139     299252                  2         0         0         0         0   \n",
       "346863      154083                  2         0         0         0         0   \n",
       "714117      220439                  3         0         0         0         0   \n",
       "1276568     308846                  2         0         0         0         0   \n",
       "1026388     273835                  3         0         0         0         0   \n",
       "1669654     370270                  3         0         0         0         0   \n",
       "\n",
       "         char_5_x  char_6_x  char_7_x  char_8_x   ...     char_29  char_30  \\\n",
       "79634           0         0         0         0   ...           0        0   \n",
       "1739874         0         0         0         0   ...           1        1   \n",
       "21887           0         0         0         0   ...           0        0   \n",
       "1311241         0         0         0         0   ...           1        1   \n",
       "1222139         0         0         0         0   ...           0        0   \n",
       "346863          0         0         0         0   ...           0        0   \n",
       "714117          0         0         0         0   ...           0        0   \n",
       "1276568         0         0         0         0   ...           0        0   \n",
       "1026388         0         0         0         0   ...           0        0   \n",
       "1669654         0         0         0         0   ...           0        0   \n",
       "\n",
       "         char_31  char_32  char_33  char_34  char_35  char_36  char_37  \\\n",
       "79634          0        0        0        0        0        0        0   \n",
       "1739874        1        1        1        1        1        1        1   \n",
       "21887          0        0        0        0        0        0        0   \n",
       "1311241        1        1        1        1        1        1        1   \n",
       "1222139        0        0        0        0        0        0        0   \n",
       "346863         0        0        0        0        0        0        0   \n",
       "714117         0        0        0        0        0        0        0   \n",
       "1276568        0        0        0        0        0        0        0   \n",
       "1026388        0        0        0        0        0        0        0   \n",
       "1669654        0        0        0        0        0        0        0   \n",
       "\n",
       "         char_38  \n",
       "79634          0  \n",
       "1739874       46  \n",
       "21887         70  \n",
       "1311241       94  \n",
       "1222139        0  \n",
       "346863        72  \n",
       "714117         0  \n",
       "1276568        0  \n",
       "1026388       83  \n",
       "1669654        0  \n",
       "\n",
       "[10 rows x 51 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing\n",
    "test = actions_test.merge(peeps, how='left', on='people_id')\n",
    "\n",
    "# Check it out...\n",
    "features.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_v1( input_dim):\n",
    "    nb_classes = 1\n",
    "    # number of convolutional filters to use\n",
    " \n",
    "    model = Sequential()\n",
    "\n",
    "  \n",
    "    model.add(Dense(100,input_dim=input_dim,activation='relu'))\n",
    "   \n",
    "  \n",
    "    model.add(Dense(100,activation='relu'))\n",
    "  \n",
    "   \n",
    "    \n",
    "    model.add(Dense(nb_classes))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    sgd = SGD(lr=0.05, decay=0, momentum=0.95, nesterov=True)\n",
    "    #sgd = SGD(lr=1e-2, decay=1e-6)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:590: DataConversionWarning: Data with input dtype int32 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:590: DataConversionWarning: Data with input dtype int32 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting the model\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features = features.as_matrix()\n",
    "scaler = preprocessing.StandardScaler().fit(features)\n",
    "features = scaler.transform(features)   \n",
    "num_test = 0.20\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels.as_matrix(), test_size=num_test, random_state=1337)\n",
    "\n",
    "model_checkpoint = ModelCheckpoint('redhat1.hdf5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "\n",
    "model= create_model_v1(input_dim)\n",
    "\n",
    "print(\"Start fitting the model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1757832 samples, validate on 439459 samples\n",
      "Epoch 1/1\n",
      "1757832/1757832 [==============================] - 57s 32us/step - loss: 0.2682 - acc: 0.8714 - val_loss: 0.2450 - val_acc: 0.8841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:590: DataConversionWarning: Data with input dtype int32 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "439459/439459 [==============================] - 7s 16us/step\n",
      "498687/498687 [==============================] - 10s 20us/step\n",
      "(439459, 1)\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train , y_train, batch_size=100, nb_epoch=1, validation_data =(X_test,y_test) ,\n",
    "          verbose=1, shuffle=True,callbacks=[model_checkpoint])\n",
    "\n",
    "test= scaler.transform(test.as_matrix())\n",
    "\n",
    "model.load_weights('redhat1.hdf5') \n",
    "proba= model.predict(X_test, verbose=1)\n",
    "test_proba = model.predict(test, verbose=1)\n",
    "\n",
    "print(np.shape(proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start predicting\n"
     ]
    }
   ],
   "source": [
    "## Out of box random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "print(\"start predicting\")\n",
    "#clf = RandomForestClassifier()\n",
    "#clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under ROC 0.9576760872130916\n",
      "(498687,)\n"
     ]
    }
   ],
   "source": [
    "preds = proba\n",
    "score = roc_auc_score(y_test, preds)\n",
    "print(\"Area under ROC {0}\".format(score))\n",
    "\n",
    "\n",
    "#test_proba = clf.predict_proba(test)\n",
    "test_preds = test_proba.flatten()\n",
    "\n",
    "print(np.shape(test_preds))\n",
    "# Format for submission\n",
    "output = pd.DataFrame({ 'activity_id' : test_ids, 'outcome': test_preds })\n",
    "\n",
    "output.to_csv('redhat.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
